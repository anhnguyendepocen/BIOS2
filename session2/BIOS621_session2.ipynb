{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIOS621 Session 2\n",
    "\n",
    "## Levi Waldron\n",
    "\n",
    "\n",
    "Welcome and outline - session 2\n",
    "========================================================\n",
    "\n",
    "* brief overview of multiple regression (Chapter 4)\n",
    "* Linear Regression as a Generalized Linear Model (Chapter 5)\n",
    "* Statistical inference for logistic regression\n",
    "\n",
    "Learning objectives - session 2\n",
    "========================================================\n",
    "\n",
    "* define generalized linear models (GLM)\n",
    "* define linear and logistic regression as special cases of GLMs\n",
    "* distinguish between additive and multiplicative models\n",
    "* define Pearson and deviance residuals\n",
    "* additional familiarity with R, including `dplyr` and `ggplot2`\n",
    "\n",
    "Multiple Linear Regression Model\n",
    "========================================================\n",
    "Systematic component:\n",
    "\n",
    "$$\n",
    "E[y|x] = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "- $x_p$ are the predictors or independent variables\n",
    "- $y$ is the outcome, response, or dependent variable\n",
    "- $E[y|x]$ is the expected value of $y$ given $x$\n",
    "- $\\beta_p$ are the regression coefficients\n",
    "\n",
    "Multiple Linear Regression Model\n",
    "========================================================\n",
    "\n",
    "Systematic plus random component:\n",
    "\n",
    "$y_i = E[y|x] + \\epsilon_i$\n",
    "\n",
    "$y_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\epsilon_i$\n",
    "\n",
    "Assumption: $\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma_\\epsilon^2)$\n",
    "\n",
    "* Normal distribution\n",
    "* Mean zero at every value of predictors\n",
    "* Constant variance at every value of predictors\n",
    "* Values that are statistically independent\n",
    "\n",
    "Generalized Linear Models\n",
    "========================================================\n",
    "* Linear regression is a special case of a broad family of models called “Generalized Linear Models” (GLM)\n",
    "* This unifying approach allows to fit a large set of models using maximum likelihood estimation methods (MLE) (Nelder & Wedderburn, 1972)\n",
    "* Can model many types of data directly using appropriate distributions, e.g. Poisson distribution for count data\n",
    "* Transformations of $Y$ not needed\n",
    "\n",
    "Components of GLM\n",
    "========================================================\n",
    "\n",
    "* **Random component** specifies the conditional distribution for the response variable\n",
    "    + doesn’t have to be normal\n",
    "    + can be any distribution in the \"exponential\" family of distributions\n",
    "* **Systematic component** specifies linear function of predictors (linear predictor)\n",
    "* **Link** [denoted by g(.)] specifies the relationship between the expected value of the random component and the systematic component\n",
    "    + can be linear or nonlinear  \n",
    "\n",
    "Linear Regression as GLM\n",
    "========================================================\n",
    "\n",
    "* **The model**: $y_i = E[y|x] + \\epsilon_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi} + \\epsilon_i$\n",
    "\n",
    "* **Random component** of $y_i$ is normally distributed:   $\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma_\\epsilon^2)$\n",
    "\n",
    "* **Systematic component** (linear predictor): $\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}$\n",
    "\n",
    "* **Link function** here is the _identity link_: $g(E(y | x)) = E(y | x)$.  We are modeling the mean directly, no transformation.\n",
    "\n",
    "Logistic Regression as GLM\n",
    "========================================================\n",
    "\n",
    "* **The model**: \n",
    "$$\n",
    "Logit(P(x)) = log \\left( \\frac{P(x)}{1-P(x)} \\right) = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}\n",
    "$$\n",
    "\n",
    "* **Random component**: $y_i$ follows a Binomial distribution (outcome is a binary variable)\n",
    "\n",
    "* **Systematic component**: linear predictor \n",
    "$$\n",
    "\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}\n",
    "$$\n",
    "\n",
    "* **Link function**: _logit_ (log of the odds that the event occurs)\n",
    "\n",
    "$$\n",
    "g(P(x)) = logit(P(x)) = log\\left( \\frac{P(x)}{1-P(x)} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(x) = g^{-1}\\left( \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}\n",
    " \\right)\n",
    "$$\n",
    "\n",
    "logit function\n",
    "================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "fig.height": "6",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "logit <- function(P) log(P/(1-P))\n",
    "plot(logit, xlab=\"Probability\", ylab=\"Log-odds\",\n",
    "     cex.lab=1.5, cex.axis=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse logit function\n",
    "================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invLogit <- function(x) 1/(1+exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "fig.height": "6,",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "plot(invLogit, xlim=c(-6, 6), cex.lab=1.5, cex.axis=1.5,\n",
    "     xlab=\"Log-odds\", ylab=\"Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additive vs. Multiplicative models\n",
    "=================================================\n",
    "\n",
    "* Linear regression is an _additive_ model\n",
    "    + _e.g._ for two binary variables $\\beta_1 = 1.5$, $\\beta_2 = 1.5$.\n",
    "    + If $x_1=1$ and $x_2=1$, this adds 3.0 to $E(y|x)$\n",
    "* Logistic regression is a _multiplicative_ model\n",
    "    + If $x_1=1$ and $x_2=1$, this adds 3.0 to $log(\\frac{P}{1-P})$\n",
    "    + Odds-ratio $\\frac{P}{1-P}$ increases 20-fold: $exp(1.5+1.5)$ or $exp(1.5) * exp(1.5)$\n",
    "\n",
    "Motivating example: contraceptive use data\n",
    "=================================================\n",
    "From http://data.princeton.edu/wws509/datasets/#cuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "cuse <- read.table(\"http://data.princeton.edu/wws509/datasets/cuse.dat\", header=TRUE)\n",
    "summary(cuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivating example: contraceptive use data\n",
    "=================================================\n",
    "No interactions:\n",
    "\n",
    "\\tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 <- glm(cbind(using, notUsing) ~ age + education + wantsMore, \n",
    "           data=cuse, family=binomial(\"logit\"))\n",
    "summary(fit1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson residuals for logistic regression\n",
    "=================================================\n",
    "Take the difference between observed and fitted values (on probability scale 0-1), and divide by the standard deviation of the observed value.\n",
    "\n",
    "* Let $\\hat y_i$ be the best-fit predicted probability for each data point, i.e. $g^{-1}(\\beta_0 + \\beta_1 x_{1i} + ...)$\n",
    "* $y_i$ is the observed value, either 0 or 1.\n",
    "\n",
    "$$\n",
    "r_i = \\frac{y_i - \\hat y_i}{ \\sqrt{ Var(\\hat y_i) }}\n",
    "$$\n",
    "\n",
    "Summing the squared Pearson residuals produces the _Pearson Chi-squared statistic_:\n",
    "\n",
    "$$\n",
    "\\chi ^2 = \\sum_i r_i^2\n",
    "$$\n",
    "\n",
    "Deviance residuals for logistic regression\n",
    "=================================================\n",
    "\n",
    "* Deviance residuals and Pearson residuals converge for high degrees of freedom\n",
    "* Deviance residuals indicate the contribution of each point to the model _likelihood_\n",
    "* Definition of deviance residuals:\n",
    "\n",
    "$$\n",
    "d_i = s_i \\sqrt{ -2 ( y_i \\log \\hat y_i + (1-y_i) \\log (1 - \\hat y_i) ) }\n",
    "$$\n",
    "\n",
    "Where $s_i = 1$ if $y_i = 1$ and $s_i = -1$ if $y_i = 0$.\n",
    "\n",
    "* Summing the deviances gives the overall deviance: $D = \\sum_i d_i^2$\n",
    "\n",
    "Model likelihood and deviance\n",
    "=================================================\n",
    "\n",
    "* The _likelihood_ of a model is the probability of the observed outcomes given the model, sometimes written as:\n",
    "    + $L(\\theta | data) = P(data|\\theta)$.\n",
    "* Deviance residuals and the difference in log-likelihood between two models are related by:\n",
    "\n",
    "$\\Delta (\\textrm{D}) = -2 * \\Delta (\\textrm{log likelihood})$\n",
    "\n",
    "Likelihood Ratio Test\n",
    "=================================================\n",
    "\n",
    "* Use to assess whether the reduction in deviance provided by a more complicated model indicates a better fit\n",
    "* It is equivalent of the nested Analysis of Variance is a nested Analysis of Deviance\n",
    "* The difference in deviance under $H_0$ is *chi-square distributed*, with df equal to the difference in df of the two models.\n",
    "\n",
    "\n",
    "Likelihood Ratio Test (cont'd)\n",
    "=================================================\n",
    "\n",
    "\\scriptsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit0 <- glm(cbind(using, notUsing) ~ -1, data=cuse, \n",
    "            family=binomial(\"logit\"))\n",
    "anova(fit0, fit1, test=\"LRT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wald test for individual regression coefficients\n",
    "=================================================\n",
    "\n",
    "* Can use partial Wald test for a single coefficient: \n",
    "    + $\\frac{\\hat{\\beta}}{\\sqrt{var(\\hat{\\beta)}}} \\sim t_{n-1}$\n",
    "    + $\\frac{\\left ( \\hat{\\beta} - \\beta_0 \\right )^2 }{var(\\hat{\\beta)}} \\sim   \\chi^2_{df=1}$ (large sample)\n",
    "* Wald CI for $\\beta$: $\\hat{\\beta} \\pm t_{1-\\alpha/2, n-1} \\sqrt{var(\\hat{\\beta})}$\n",
    "* Wald CI for odds-ratio: $e^{\\hat{\\beta} \\pm t_{1-\\alpha/2, n-1} \\sqrt{var(\\hat{\\beta})}}$\n",
    "\n",
    "_Note_: Wald test confidence intervals on coefficients can provide poor coverage in some cases, even with relatively large samples\n",
    "\n",
    "\n",
    "\n",
    "Lab Exercises\n",
    "=================================================\n",
    "\n",
    "1. What is the mean fraction of women using birth control for each age group? Each education level? For women who do or don't want more children?\n",
    "     - Hint: look at the \"data wrangling\" cheat sheet functions `mutate`, `group_by`, and `summarize`\n",
    "2. Based on ```fit1```, write on paper the model for expected probability of using birth control.  Don't forget the logit function.\n",
    "3. Based on ```fit1```, what is the expected probability of an individual 25-29 years old, with high education, who wants more children, using birth control? Calculate it manually, and using `predict(fit1)`\n",
    "4. Based on ```fit1```: Relative to women under 25 who want to have children, what is the predicted increase in odds that a woman 40-49 years old who does _not_ want to have children will be taking birth control?\n",
    "5. Using a likelihood ratio test, is there evidence that a model with interactions improves on ```fit1``` (no interactions)?\n",
    "6. Which, if any, variables have the strongest interactions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
